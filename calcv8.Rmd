---
title: "Momentum Crashes"
output:
  html_document: default
  'html_document:': default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, packloading}
library(dplyr)
library(tidyquant)
library(tidyverse)
library(plyr)
```

```{r, read data}
library(readr)

df = read_csv2("sp500.csv",col_names = TRUE, col_types = cols(`date` = col_character(), 
        `mcap` = col_number(), `close` = col_number(), 
        `tot_ret` = col_number()))

names(df)[2]  = "symbol"

df[is.na(df)] = 0

devtools::unload("readr")
```

```{r, prepare data}
library(bsts)
##
## Cleaning some data, removing some dates
##
df$date =  as.Date(df$date, format = '%d.%m.%Y')

portstart_date = c("2000-01-01")

df = dplyr::filter(df, date > portstart_date)

df = df %>% dplyr::filter(close != 0) %>% dplyr::filter(mcap != 0) %>% dplyr::select(-(tot_ret))

#month_day = LastDayInMonth(df$date) %>% as.Date()
#month_day = month_day %>% unique()

transform(df, date = bsts::LastDayInMonth(df$date))

#df = dplyr::filter(df, date == month_day) 

df = df %>% group_by(symbol) %>% arrange(date) 

devtools::unload("bsts")
```

```{r, return calc pers stock}
# Return calculation for each stock in. More accurate then the "simple" lead - var /var method 
# Normal methods gives high random scores, as it tries to calculate with next col
# This method returns NA when there is no other date to calculate to (no next lead)

return_calculations = function(portfolio){
  reb_month =  unique(portfolio$date) # Find all unique stocks 
  reb_stock = unique(portfolio$symbol) # Find all unique dates 
  temp_holder = NULL # working variable 
  temp_holder2 = NULL # Working variable 
  pb = txtProgressBar(min = 0, max = length(reb_stock), initial = 0, style = 3) # Progressbar 
  count = 1 # Counter to see time remaining
    for (j in 1:length(reb_stock)){
      temp_holder = portfolio %>% dplyr::filter(symbol == reb_stock[j])
      temp_holder$return  = ((lead(temp_holder$close) - temp_holder$close)  / temp_holder$close)
      temp_holder2 = rbind(temp_holder,temp_holder2) 
      count = count + 1
      vv = setTxtProgressBar(pb,count)
    }
  return(temp_holder2)
}  

df = return_calculations(df)
df = df %>% dplyr::filter(date < "2021-10-01") # Last calculations does not have anything above to calculate return from, therefor rem. 
```

```{r, 2:12 month return to messure momentum}
# This creates 12 cols, these cols will tell you if you sold it today, what will be the return 

return_function = function(portfolio,period){
  x = ((portfolio$close - lag(portfolio$close, n = period))  / lag(portfolio$close, n = period))
  return(x)
}

mom_2_12= function (portfolio){ # Defining function
  uniq_stocks =  unique(portfolio$symbol) # finds each stock to calc returns
  temp_holder = 0 %>% as.data.frame()
  temp_holder2 = 0 %>% as.data.frame()
  temp_holder3 = 0 %>% as.data.frame()
  count = 0
  pb = txtProgressBar(min = 0, max = length(uniq_stocks), initial = 0, style = 3) # progress bar
   z = 0 %>% as.data.frame()
  for (i in 1:length(uniq_stocks)){ # for each date we have in the portfolio do this
      z = portfolio %>% dplyr::filter(uniq_stocks[i] == symbol)
      count = count + 1 # Adds 1 to the counter for progressbar 
       setTxtProgressBar(pb,count) # Starting the progress bar
      for(j in 2:12) {
        #temp_holder  = momentum(z$return, n=j)
        temp_holder = return_function(z, j)
        name = paste0("mom", sep = "_", j)
        z[[name]] =  temp_holder 
        if (j == 12){
          temp_holder2  = bind_rows(temp_holder2, z)
        } 
     }
    }
  return(temp_holder2)
}  

test  = mom_2_12(df)
df = test %>% slice(-c(1)) # Due to bind with one Zero, there is a redundant row, this is removed here. 
test = NULL 
```

```{r, scrubbing data, making som return rankings}
# We can get data that is calculated to inf! this is due to the table sometimes provides us with nothing to calculate to or from \ incase a delesting etc. Therefor we have to convert info to get Zero as a value, if we filter out inf we will remove to many returns! 
#df = df %>% dplyr::select(-1) # just removing a col that was not supose to be there (NB! HARD CODED )
library(matrixStats)

table_scrubber = function() {
  df[7:17] = na_if(df[7:17], 0)
  df[sapply(df, is.infinite)] = NA
  df[sapply(df, is.nan)] = NA
}

#df[df[7:17] == 0] = NA
table_scrubber()
df$available_returns = rowSums(!is.na(df[7:17])) # compute number of available returns

df$cum_return = matrixStats::rowProds(1+as.matrix(df[7:17]), na.rm=T) %>% log()

table_scrubber() # Just makeing sure my data is nice and shiny 

devtools::unload("matrixStats")
```

```{r, actual ranking, over 8 month returns, normalizing values for quantiles}
# Before we input it into quantiles we have to normalize our data, as it can only recive 0 and 1. 
# Our data set goes from -1 to 1 

df$cum_return_norm = df$cum_return / df$available_returns #Normalising our returns devided on number on total number of rets
df = df %>% dplyr::filter(available_returns >= 8) #%>% dplyr::filter(return != 0)# Above 8 monthly returns in ranking
x = df$cum_return_norm 
df$norm_norm_cret = (x-min(x))/(max(x)-min(x))

x = NULL
```

```{r, putting into monthly deciles}
#This 8 month returns, is it right or not ? Since i will recive 6 months where there are Zero companies that has 8 month of ret

decile_seperation = function(portfolio){
  x = portfolio #%>% dplyr::distinct(norm_norm_cret, .keep_all = T)
  reb_month =  unique(x$date) # Finding all unique dates 
  temp_holder1 = NULL
  temp_holder2 = NULL # Empty working var 
  temp_holder3 = NULL # Empty working var 
  temp_holder4 = NULL # Empty working var
  pb = txtProgressBar(min = 0, max = length(reb_month), initial = 0, style = 3) # progress bar
  count = 1 #counter for usage in progress bar
    for (j in 1:length(reb_month)){ # Takes all months with the mentioned criteria above.
      temp_holder1 = x %>% dplyr::filter(date == reb_month[j]) # filter each dates so we have one specific month
      temp_holder2$quantile = cut(temp_holder1$norm_norm_cret, # put it into dociles, based on monthly return
          quantile((temp_holder1$norm_norm_cret),probs=seq(from=0,to=1,by=1/10),na.rm =T),
          #quantile((normalized_cumalative),probs=seq(from=0,to=1,by=1/10),na.rm =T),
          include.lowest=TRUE, 
          labels=FALSE) # %>% as.list() %>% as.integer()
       temp_holder3= add_column(temp_holder1 ,as_tibble(temp_holder2)) # adds the decile score to the table 
       temp_holder4= bind_rows(temp_holder3 ,temp_holder4)  # Binds the score and the folder for a stock and date
       count = count + 1 # Adds 1 to the counter for progressbar 
       setTxtProgressBar(pb,count) # Starting the progress bar
    }  
  return(temp_holder4) # Returns from function a entire dataset with quantiles attached.
}

df = as_tibble(decile_seperation(df)) # calls the function on tibble df, and saves as dfa  

names(df)[names(df) == "value"] <- "quantile" # Renames the colume value to quantile.  

```

```{r, Monthly value weighted function}
# Creates monthly value weights per stock 
v_weights= function (portfolio){ # Defining function
  reb_month =  unique(portfolio$date) # finds each re-balancing months from the portfolio
  temp_holder = 0 %>% as.data.frame()
  z = 0 
  count = 0 
  pb = txtProgressBar(min = 0, max = length(reb_month), initial = 0, style = 3) # progress bar
    for (i in 1:length(reb_month)){ # for each date we have in the portfolio do this 
      z = portfolio %>% dplyr::filter(reb_month[i] == date) # Select the first date on the list, filter out the rest
      count = count + 1 # Adds 1 to the counter for progressbar 
      setTxtProgressBar(pb,count) # Starting the progress bar
        for (j in 1:10){ 
          x = z
          a = x %>% dplyr::filter(quantile == j)
          tot_w = sum(a$mcap)  
          a$vw  = (a$mcap/tot_w) %>% as.data.frame()
          temp_holder = bind_rows(a,temp_holder) 
          if (j == 1 && i == 1) { # This is only here to remoe the one binding col!
             temp_holder = temp_holder %>% slice(-c(nrow(temp_holder)))
             } 
        }
      
    }
  return(temp_holder)
}  
        
df  = v_weights(df)
df = df %>% slice(-c(ncol(df)))

#names(df)[ncol(df)] = 'value_w'

dfx = df %>% dplyr::filter(quantile == 1) %>% dplyr::filter(date == "2008-12-31") # Checking that weights sum to one 
sum(dfx$vw) # OK if it sums to one
dfx = NULL
```

```{r, Making bot and top quabtiles}
top_1 = df %>% dplyr::filter(quantile == 10) %>% arrange(date) # making the best performance portf
mid_1 = df %>% dplyr::filter(quantile == 5) %>% arrange(date)  # med performance portfolio based 
bot_1 = df %>% dplyr::filter(quantile == 1) %>% arrange(date)  # worst performance portfolio based 
```

```{r, retriving market index for sp500, cleaning and formating, THIS NEEDS TUNING IF CHANGE OF DATES!}
## CREATING A MONTHLY DATASET for SP500!
##
library(bsts)
library(openair)

from = today() - years(40)

sp500 = tq_get(c("^GSPC"), get = "stock.prices", from = from) %>%
    group_by(symbol)


sp500$date =  as.Date(sp500$date, format = '%Y-%m-%d')

sp500 = dplyr::filter(sp500, date > portstart_date)

month_day = LastDayInMonth(sp500$date) %>% unique() %>% as.Date()

sp500 = sp500 %>% group_by(symbol)

selecter = c("symbol", "date", "close") # Variables to have in top and bot tibble
sp500 = dplyr::select(sp500,all_of(selecter)) 

sp500[1] = "SP500"

portfolio = sp500

date_filter = function(portfolio) {
  counter = 0
  start_date = portfolio[1,2]
  start_date = start_date$date %>% as.Date(format = '%Y-%m-%d')
  end_date = portfolio[nrow(portfolio),2]
  end_date = end_date$date %>% as.Date(format = '%Y-%m-%d')
  years = seq(from = start_date, to = end_date, by = 'year')
  years = length(years)
  temp_holder1 = NULL
  temp_holder2 = NULL
  temp_holder3 = NULL
  pb = txtProgressBar(min = 0, max = years, initial = 0, style = 3) # progress bar
  for (i in 1:years) {
    year_counter = (2000 + counter) ###############HARDCODED 1989 NEEDS TO BE CHANGED ACCORDING TO YEAR! ###########
    x = selectByDate(portfolio, year = year_counter ) 
    counter = counter + 1
    setTxtProgressBar(pb,counter) # Starting the progress bar
    for (j in 1:12){
      #temp_holder1 = x[months(x$date) %in% tolower(month.name[j]),]
      temp_holder1 = x$date[lubridate::month(x$date) == j] 
      temp_holder1 = temp_holder1[length(temp_holder1)]
      temp_holder3 = x %>% dplyr::filter(x$date == temp_holder1) 
      temp_holder2 = rbind(temp_holder2,temp_holder3)
    }
      
  }
  return(temp_holder2)
}

sp500 = date_filter(sp500)

sp500 = sp500 %>% arrange(date)

sp500$return = ((lead(sp500$close) - sp500$close)  / sp500$close)

sp500[is.na(sp500)] = 0
sp500[sapply(sp500, is.infinite)] = 0

sp500$cum_ret = cumprod(1 + sp500$return) 

sp500 = sp500 %>% dplyr::filter(cum_ret != 0) %>% dplyr::filter(cum_ret != 1)

devtools::unload("bsts")
```

```{r, cumalative returns for each portfolio calc, warning = FALSE}
###
### Calculates returns on specific portfolios, invest 1 dollar in time Zero and does compounding Value WEIGHTED
###### 
selecter = c("symbol", "date", "return", "vw") # Variables to have in top and bot tibble
top = dplyr::select(top_1,all_of(selecter)) # Selects from selecter
mid = dplyr::select(mid_1,all_of(selecter)) # Selects from selecter
bot = dplyr::select(bot_1,all_of(selecter)) # Selects from selecter


cumalative_ret_portfolio = function (portfolio){ # Defining function
reb_month =  unique(portfolio$date) # finds each re-balancing months from the portfolio
tot_ret = c() # empty vector 
sum_w = 0
temp = 0 
  for (i in 1:length(reb_month)){ # for each date we have in the portfolio do this 
    if (i == 1){  # First round do this 
      z = portfolio %>% dplyr::filter(reb_month[i] == portfolio$date) # Select the first date on the list, filter out the rest 
      ret = (1+z$return) * z$vw  # Investing 1 dollar divided by stocks multiplied with returns
      tot_ret[i]  = sum(ret) # Summarize all the returns from investing one dollar 
    }
    if (i > 1){ # When its beyond start date, (t+1). Do the following
      z = portfolio %>% dplyr::filter(reb_month[i] == portfolio$date) # Filter out the dates not needed
      ret = tot_ret[i-1] * z$vw * (1+z$return) #Returns * the weights 
      tot_ret[i]  = sum(ret) # Sum it all up to reinvest 
    }
  }
return(tot_ret) #returns the calculations out of the loop
}

##
## This section retrives a string of numbers (return per rebalancing period)
##

top_score = cumalative_ret_portfolio(top) # runs the script on top portfolio 
mid_score = cumalative_ret_portfolio(mid) # runs on bot portf.
bot_score = cumalative_ret_portfolio(bot) # runs on bot portf.
```

```{r, WML weighting and calculations}
#creating wml portfolio
wml_weights= function (portfolio){ # Defining function
  reb_month =  unique(portfolio$date) # finds each re-balancing months from the portfolio
  temp_holder = 0 %>% as.data.frame()
  z = 0 
  count = 0 
  pb = txtProgressBar(min = 0, max = length(reb_month), initial = 0, style = 3) # progress bar
    for (i in 1:length(reb_month)){ # for each date we have in the portfolio do this 
      z = portfolio %>% dplyr::filter(reb_month[i] == date) # Select the first date on the list, filter out the rest
      count = count + 1 # Adds 1 to the counter for progressbar 
      setTxtProgressBar(pb,count) # Starting the progress bar
          x = z
          tot_w = sum(x$mcap)  
          x$vw  = (x$mcap/tot_w) %>% as.data.frame()
          temp_holder = bind_rows(x,temp_holder) 
          if (i == 1) { # This is only here to remoe the one binding col!
             temp_holder = temp_holder %>% slice(-c(nrow(temp_holder)))
             } 
        }
      return(temp_holder)
    }
  
wml_cumalative_ret_portfolio = function (port){ # Defining function
reb_month =  unique(port$date) # finds each re-balancing months from the portfolio
tot_ret = c() # empty vector 
sum_w = 0
temp = 0 
  for (i in 1:length(reb_month)){ # for each date we have in the portfolio do this 
    if (i == 1){  # First round do this 
      z = port %>% dplyr::filter(reb_month[i] == port$date) # Select the first date on the list, filter out the rest 
      #z = z %>% dplyr::filter(ret_inv != 0) 
      ret = (1+z$ret_inv) * z$vw  # Investing 1 dollar divided by stocks multiplied with returns
      tot_ret[i]  = sum(ret) # Summarize all the returns from investing one dollar 
    }
    if (i > 1){ # When its beyond start date, (t+1). Do the following
      z = port %>% dplyr::filter(reb_month[i] == port$date) # Filter out the dates not needed
      tot_w = sum(z$vw)
      ret = (tot_ret[i-1]/tot_w)* z$vw * (1+z$ret_inv) #Returns * the weights 
      tot_ret[i]  = sum(ret) # Sum it all up to reinvest 
    }
  }
return(tot_ret) #returns the calculations out of the loop
}

bot_1$ret_inv = bot$return * -1   # Inverting returns 
top_1$ret_inv = top$return        # just adding the same on top for easier merging
wml_score = rbind(top_1,bot_1)    # Binding the to together 

wml_score_parent  = wml_weights(wml_score) # finding weights for wml
wml_score = wml_cumalative_ret_portfolio(wml_score_parent)

dfx = wml_score_parent %>% dplyr::filter(date == "2010-12-31") # Checking that weights sum to one 
sum(dfx$vw) # OK if it sums to one
# dfx = NULL
```

```{r, just renaming some cols, and merging tables}
##
# Takes the dates and merges then with the scores, making a more user friendly experience
##
scores = function (portfolio, parent_portfolio){ # makes function
  portfolio = portfolio %>% as_tibble() # converts the score into a tibble for easier processing 
  (portfolio)[1] = "cum_rets"  # Rename the cumalative returns 
  dates = parent_portfolio$date  %>% as.Date() %>% unique() # Find the dates from the parent calulations (pre last function)
  portfolio$date  =  dates  # takes the dates and put them into tbe portfolio
  return(portfolio) # Returns resaults 

} 

wml_score_parent = wml_score_parent %>% dplyr::select(all_of(selecter))

top_score_reb = scores(top_score, top) #Calls the function on the score and the parrent 
mid_score_reb = scores(mid_score, mid) # same but for mid score 
bot_score_reb = scores(bot_score, bot) # same but for bot score  bot_score_inverse
wml_score_reb = scores(wml_score, wml_score_parent)
```

```{r, combinding all tables from above baed on date}
total_table = function(){ 
  if ((top_score_reb$date == bot_score_reb$date) && (top_score_reb$date == bot_score_reb$date)) {
    total_score = NULL
    total_score$date  = as_tibble(top_score_reb$date)
    total_score$top = top_score_reb$cum_rets
    #total_score$mid = mid_score_reb$cum_rets # removed, no need to have it in
    total_score$bot = bot_score_reb$cum_rets
    total_score$wml = wml_score_reb$cum_rets
  return(total_score)
  }
}


total_score = as.data.frame(total_table()) # Saves the output as dataframe, so we can translate date to date
names(total_score)[names(total_score) == "value"] <- "date"
total_score[,1] = total_score$date  %>% as.Date() # Converts date to date format
```

```{r, importing fama franch data}
# Donwload research data from https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_Factors_CSV.zip
# Select monthly dataset. 
# Remember to scrub the data! Add Date as a column (or else it gets indexed) # Remove yearly data at the bottom 
# Remove notes top and bottom on the file, or else you will get strange data. 

ff_data = read.csv(file="F-F_Research_Data_Factors.CSV", sep=",", header = TRUE) # load file in working directory, seperation is , 
ff_data$date = ff_data$date %>%  ym()  #put the date into usable format in tune with our other datasets
ff_data = ff_data %>% dplyr::filter(date > "1990-01-01")  # Filter out everydate below 1990-09-01

day(ff_data$date) = days_in_month(ff_data$date) # Changing the day in our dataset to match the other data (ie last day of month)
ff_data$date = ff_data$date  %>% as.Date()

###
### MATCHING DATES AGAIN TO MAKE SURE ITS IN ORDER!!!!! I HATE DATES ! 
day(total_score$date) = days_in_month(total_score$date) # to match up with ff_dates
day(total_score$date) = days_in_month(total_score$date) 
day(sp500$date) = days_in_month(sp500$date) 
```

```{r, converting FF data to percentages}
# Devide by 100 to get the percentage and not the "percentage" :)
ff_data$ff_mkt_rf = ff_data$Mkt.RF/100
ff_data$ff_smb = ff_data$SMB/100
ff_data$ff_hml = ff_data$HML/100
ff_data$ff_rf = ff_data$RF/100
```

```{r, syncing the dates of ff data with other dates }
#
# Goal: Take data from ff_data, regarding risk free rate etc. Filter it so we can fit it into the calculated dataset
#

locate_ffdates = function(data){
  uniq_dates = unique(total_score$date)
  temp_var1 = NULL
  temp_var2 = NULL
  for (i in 1:length(uniq_dates)){   # Goes through all dates in total_score
    temp_var1   = data %>% dplyr::filter(date == uniq_dates[i])# filters out all the dates that are not in totalscore.
    temp_var2= bind_rows(temp_var1 ,temp_var2)
  }
  return(temp_var2) #Returns the data 
}

total_score$date = total_score$date %>% as.Date() # just making sure dates are in order as usual before i put it into the next func

#ff_data = ff_data %>% arrange(date) %>% filter(date <= total_score$date[1])
ff_dates = locate_ffdates(ff_data) #using the function on the FF data to get Risk free return and other data

sp500_dates = locate_ffdates(sp500)

selecter = c("date", "cum_ret") # Variables to have in top and bot tibble
sp500_dates2 = sp500_dates %>% ungroup() %>%  dplyr::select(all_of(selecter))
names(sp500_dates2)[2] = "sp500_cumret" 
  
total_score = merge(total_score, ff_dates, by.x="date", by.y="date") # Moving the dates into 
total_score = merge(total_score, sp500_dates2, by.x="date", by.y="date")
```

```{r, graphing the end returns}
# Visualization of the scores 
colors <- c("top" = "blue", "mid" = "red", "bot" = "orange", "wml" = "green" , " ff_mkt_rf" = "pink", " ff_rf" = "black")
total_score$date = total_score$date %>% as.Date()  
#total_score$wml = total_score$wml %>% as.data.frame()

#
# Return of sp 500 needs to be inserted 
#


ggplot(total_score, aes(x = date)) + # Uses main dataset
       geom_line(aes(y = top, color = "top"), size = 1) +
       #geom_line(aes(y = mid, color = "mid" ), size = 1) + 
       geom_line(aes(y = bot, color = "bot"), size = 1) + 
       geom_line(aes(y = wml, color = "wml"), size = 1) + 
       geom_line(aes(y = sp500_cumret, color = "black"), size = 1)+
       #geom_line(aes(y = ff_mkt_rf, color = " ff_mkt_rf"), size = 1) +
       #geom_line(aes(y = ff_rf, color = " ff_rf"), size = 1) +  # NOT CUMULATIVE
       labs(x = 'Date',
       y = 'Cumulative Returns',
       title = 'Portfolio Cumulative Returns') +
    scale_y_continuous(breaks = seq(0,10,1)) +
    scale_x_date(date_breaks = '5 year',
               date_labels = '%Y',) +
    scale_color_manual(values = colors)

```

```{r, cumalative returns for the ff data}
# Producing cumalative returns for the FF data
total_score$cu_ff_mkt_rf =  cumprod(1+total_score$ff_mkt_rf)
total_score$cu_ff_smb =  cumprod(1+total_score$ff_smb)
total_score$cu_ff_hml =  cumprod(1+total_score$ff_hml)
total_score$cu_ff_rf =  cumprod(1+total_score$ff_rf)
```

```{r, plotting with some ff data}
colors <- c("top" = "blue", "bot" = "orange", "wml" = "green" , " cu_ff_mkt_rf" = "red", " sp500" = "black")
total_score$date = total_score$date %>% as.Date()  

ggplot(total_score, aes(x = date)) + # Uses main dataset
       geom_line(aes(y = top, color = "top"), size = 1) +
       geom_line(aes(y = bot, color = "bot"), size = 1) + 
       #geom_line(aes(y = mid, color = "mid"), size = 1) + 
       geom_line(aes(y = wml, color = "wml"), size = 1) + 
       geom_line(aes(y = cu_ff_mkt_rf, color = " cu_ff_mkt_rf"), size = 1) + 
       geom_line(aes(y = sp500_cumret, color = "sp500"), size = 1)+
       labs(x = 'Date',
       y = 'Cumulative Returns',
       title = 'Portfolio Cumulative Returns') +
    scale_y_continuous(breaks = seq(0,10,1)) +
    scale_x_date(date_breaks = '5 year',
               date_labels = '%Y') +
    scale_color_manual(values = colors)
```

```{r, regression on wml}
# I belive this might be redundant
#
total_score$return_wml_reg = total_score$wml - total_score$cu_ff_rf
total_score

#Regressing the returns
ff_reg = lm(return_wml_reg ~  ff_mkt_rf + ff_smb + ff_hml, data = total_score)
summary(ff_reg)
```

```{r, calculating returns for deciles and formating the tables}
#
# Before implementing a time series we need to create top and bot into monthly returns
#
month_ret = function (portfolio){ # Defining function
  reb_month =  unique(portfolio$date) # finds each re-balancing months from the portfolio
  tot_ret = c() # empty vector 
  sum_w = 0
  temp = 0 
    for (i in 1:length(reb_month)){ # for each date we have in the portfolio do this 
      z = portfolio %>% dplyr::filter(reb_month[i] == portfolio$date) # Select the first date on the list, filter out the rest 
      ret = (z$return)  # Investing 1 dollar divided by stocks multiplied with returns
      tot_ret[i]  = sum(ret) # Summarize all the returns from investing one dollar 
    }
return(tot_ret) #returns the calculations out of the loop
}

month_ret_top = month_ret(top) %>% bind_cols(unique(top$date)) 
names(month_ret_top)[1] = "ret_mont_top"
names(month_ret_top)[2] = "date"

month_ret_bot = month_ret(bot) %>% bind_cols(unique(bot$date))
names(month_ret_bot)[1] = "ret_mont_bot"
month_ret_tot = bind_cols(month_ret_top,month_ret_bot$ret_mont_bot)
names(month_ret_tot)[3] = "ret_mont_bot"

month_ret_tot = month_ret_tot %>% arrange(date)

month_ret_tot = bind_cols(month_ret_tot,sp500_dates$return)
names(month_ret_tot)[4] = "sp500_ret"

month_ret_tot = month_ret_tot %>% relocate(date, .before = ret_mont_top)# Just OCD kicking in, moving date to front col 

month_ret_tot %>% head()
```

```{r, calculating betas, making some time series for top and bot}
beta = cov(total_score$top, total_score$sp500_cumret)/var(total_score$sp500_cumret)

ts_sp500_ret = ts(sp500_dates$return, start = c(2005, 1), freq = 12)
ts_top_ret = ts(month_ret_tot$ret_mont_top , start = c(2005, 1), freq = 12)
ts_bot_ret = ts(month_ret_tot$ret_mont_bot , start = c(2005, 1), freq = 12)

##
## Make a risk free rate ts ? is it neccecery?! 

CAPM.beta(ts_top_ret, ts_sp500_ret, Rf = 0) # THIS Works in our test!  This is just a dev test

beta = cov(ts_top_ret, ts_sp500_ret)/var(ts_sp500_ret) # This is equal to the one above, to check the function! 
total_score$alpha = total_score$wml - total_score$ff_rf - beta * (total_score$ff_mkt_rf - total_score$ff_rf)
```

```{r, normalizing returns, and 6m rolling regression to get Betas}
library(rollRegres)

normalizefunc = function(portfolio, colnumb){
  x = portfolio[colnumb]
  y = (x-min(x))/(max(x)-min(x))
  return(y)
}

month_ret_tot$norm_ret_mont_top = normalizefunc(month_ret_tot, 2) 
month_ret_tot$norm_ret_mont_bot = normalizefunc(month_ret_tot, 3)
month_ret_tot$norm_sp500_ret = normalizefunc(month_ret_tot, 4)

month_ret_tot$norm_ret_mont_top = as.numeric(as.character(unlist(month_ret_tot$norm_ret_mont_top)))
month_ret_tot$norm_ret_mont_bot = as.numeric(as.character(unlist(month_ret_tot$norm_ret_mont_bot)))
month_ret_tot$norm_sp500_ret = as.numeric(as.character(unlist(month_ret_tot$norm_sp500_ret)))

month_ret_tot[sapply(month_ret_tot, is.infinite)] = 0.99999 # Dummy encoding
month_ret_tot[month_ret_tot == 0] <- 0.000001 # Dummy encoding
month_ret_tot[month_ret_tot == 1] <- 0.999999 # Dummy encoding

reg_top = roll_regres(norm_ret_mont_top ~ norm_sp500_ret, month_ret_tot, width = 6, #Beta top vs SP500, 6 month window
            do_compute = c("sigmas", "r.squareds", "1_step_forecasts"))

reg_bot = roll_regres(norm_ret_mont_bot ~ norm_sp500_ret, month_ret_tot, width = 6, #Beta top vs SP500, 6 month window
            do_compute = c("sigmas", "r.squareds", "1_step_forecasts"))


reg_top_sum = bind_cols(month_ret_tot$date ,as.data.frame(reg_top$coefs))
reg_bot_sum = bind_cols(month_ret_tot$date ,as.data.frame(reg_bot$coefs)) 

names(month_ret_tot)[5] = "norm_ret_mont_top"
names(month_ret_tot)[6] = "norm_ret_mont_bot"
names(month_ret_tot)[7] = "norm_ret_sp500"

names(reg_top_sum)[1] = "date"
names(reg_top_sum)[3] = "beta_top"

names(reg_bot_sum)[1] = "date"
names(reg_bot_sum)[3] = "beta_bot"

reg_top_sum = reg_top_sum %>% na.omit() 
reg_bot_sum = reg_bot_sum %>% na.omit()

reg_top_sum$date = reg_top_sum$date %>% as.Date()

devtools::unload("rollRegres")
```

```{r, plotting log normalized beta}
# Choose from and too dates here to zoom in on graph
from_date = "2008-12-30"
to_date = "2011-01-01"
##
##

filtered_reg_top_sum = reg_top_sum %>% dplyr::filter(date > from_date) %>% dplyr::filter(date < to_date)
filtered_reg_bot_sum = reg_bot_sum %>% dplyr::filter(date > from_date) %>% dplyr::filter(date < to_date)


colors <- c("top" = "blue", "bot" = "orange")
ggplot(filtered_reg_top_sum, aes(x = date)) + # Uses main dataset
       geom_line(aes(y = beta_top, color = "top"), size = 0.75) +
       geom_line(data = filtered_reg_bot_sum, aes(y = beta_bot, color = "bot"), size = 0.75) +
       labs(x = 'Date',
       y = '6 month rolling log beta ',
       title = 'Top and bot betas') +
    scale_y_continuous(breaks = seq(-5,5,1)) +
    scale_x_date(date_breaks = '1 year',
               date_labels = '%Y') +
    scale_color_manual(values = colors)
```

```{r, plotting alpha}
ggplot(data=total_score,aes(x=date)) + geom_line(aes(y=alpha, color="alpha"),colour="#009682")+
  xlab("Date")+
  ylab("Alpha")
```

```{r, Alpa messurements }
mean(total_score$alpha)
count(total_score$alpha > 0)
count(total_score$alpha < 0)
```

```{r, bearmarket indicator}
# Recession indicators retrived from https://fred.stlouisfed.org/series/USREC

rec_ind = read.csv("USREC.csv")

rec_ind$date= rec_ind$DATE %>% as.Date()
rec_ind= dplyr::select(rec_ind, c(date, USREC))

day(rec_ind$date)<-days_in_month(rec_ind$date)

dates_rec_ind = locate_ffdates(rec_ind) #using the function on the FF data to get Risk free return and other data
  
total_score = merge(total_score, dates_rec_ind, by.x="date", by.y="date") # Moving the dates into 

total_score$bear_market = total_score$USREC*6.5

ggplot(data=total_score,aes(x=date)) + 
            geom_area(aes(y=USREC,color="red"),fill=rgb(red = 1, green = 0, blue = 0, alpha = 0.5))+
            geom_line(aes(y=top, color="top"))+
            xlab("Date")+
            ylab("Dollar value of investment")+
            ylim(0,6.5)

```

```{r, value at risk }
VaR(total_score$top) # This has to be investigated 
VaR(total_score$ff_mkt_rf)

```

```{r, sharp-ratio}
df_sharpe_wml = total_score[,c("date","top")]
df_sharpe_wml = df_sharpe_wml %>% as.data.frame()
row.names(df_sharpe_wml)= as.Date(df_sharpe_wml$date) 
#df_sharpe_wml = df_sharpe_wml %>% dplyr::select(wml)

mean_rf = mean(total_score$ff_rf)

# This is done becouse we want to 
df_sharpe_wml <- xts(x = df_sharpe_wml[, -1], # use all columns except for first column (date) as data
                   order.by = as.Date(df_sharpe_wml$date) # Convert Date column from factor to Date and use as time index
                   )

SharpeRatio(df_sharpe_wml[, 1, drop = FALSE]  ,Rf=mean_rf, FUN="StdDev")

df_sharpe_mkt = total_score[,c("date","ff_mkt_rf")]
#SharpeRatio(df_sharpe_mkt,Rf=mean_rf, FUN="StdDev", drop =FALSE)

```

```{r, testing top for stationarity, white noise auto regression}
library(aTSA)
library(forecast)

# from calculating betas we have the ts from top bot and s&p

testing_ts = function(timeseries, lag) {
  plot(timeseries)
  plot(timeseries^2)
  acf(timeseries, lag.max=lag)
  adf.test(timeseries) # p-value > 0 .05 therefor we reject the hypothesis that it is nonstationary. Therefor it is stationary.
  pacf(timeseries)
  Box.test(timeseries, lag = lag, type = "Ljung")
  decompose_ts_top = decompose(ts_top_ret)
  decompose_ts_top %>% plot()
}

decompose_ts_top = diff(ts_top_ret, differences = 1)  # creating a first order decomposition of the time series
testing_ts(decompose_ts_top,6)
lambda = BoxCox.lambda(decompose_ts_top)

#auto.arima(decompose_ts_top,D=1, approximation = FALSE, lambda = lambda, parallel = TRUE, stepwise=FALSE, num.cores = 30 )
```

```{r}
library(fGarch)

ts_top_garch = garchFit(~aparch(1,1), data=decompose_ts_top, trace=F, delta = 2, include.delta = F)
summary(ts_top_garch)
```

```{r, volatility calculations}

vol_calc = function (data){
  out = volatility(data, n = 6, calc = "close", N = 12, mean0 = FALSE)
  return(out)
}

month_ret_tot$top_vol = vol_calc(month_ret_tot$norm_ret_mont_top)
month_ret_tot$sp500_vol =  vol_calc(month_ret_tot$norm_ret_sp500)
month_ret_tot$bot_vol = vol_calc(month_ret_tot$norm_ret_mont_bot)

```

```{r, making time-series of sp500 for testing}
temp_sp500_ret = month_ret_tot %>% dplyr::select("sp500_ret","date") %>% arrange(date)
temp_close_sp = sp500_dates  %>% ungroup() %>% dplyr::select("close","date") %>% arrange(date)
temp_sp500_rvol = month_ret_tot %>%  dplyr::select("sp500_vol","date") %>% arrange(date)

row.names(temp_sp500_rvol) = temp_sp500_rvol$date
row.names(temp_close_sp) = temp_close_sp$date
row.names(temp_sp500_ret) = temp_sp500_ret$date

# temp_close_sp = temp_close_sp %>% dplyr::select(-c("date"))
# temp_sp500_ret = temp_sp500 %>% dplyr::select(-c("date"))
# temp_sp500_rvol = temp_sp500_rvol %>% dplyr::select(-c("date"))

ts_sp500_close = ts(temp_close_sp[,1], start = c(2000, 10), freq = 12) # closing prices
ts_sp500_ret = ts(temp_sp500_ret[,1], start = c(2000, 10), freq = 12) # returns  
ts_sp500_rvol = ts(temp_sp500_rvol[,1], start = c(2000, 10), freq = 12) # real volatility
```


<!-- ```{r} -->
<!-- library(quantmod) -->
<!-- library(xts) -->
<!-- library(PerformanceAnalytics) -->
<!-- library(rugarch) -->
<!-- library(ggplot2) -->



<!-- garch_sp500_spec = ugarchspec(mean.model = list(armaOrder = c(0,0)), -->
<!--                    variance.model = list(model = "gjrGARCH"), -->
<!--                    distribution.model = 'sstd') -->

<!-- garch_sp500_fit_close = ugarchfit(garch_sp500_spec, ts_sp500_close) -->

<!-- coef(garch_sp500_fit_close) -->
<!-- #garch_top_model = ugarchfit(data = ts_sp500_ret, spec = garch_top_spec, cond.dist="std" ) -->

<!-- vol_sp500_garch = ts(garch_sp500_fit_close@fit$sigma^2,start=c(2000,10),end=c(2010,12),frequency = 12) -->

<!-- plot(vol_sp500_garch,xlab="",ylab="",main="garch_sp500_fit_close") -->

<!-- plot(garch_sp500_fit_close, which = "all") -->

<!-- x = sqrt(12) * garch_sp500_fit_close@fit$sigma -->
<!-- plot(x,type="l") -->

<!-- y = ts_sp500_rvol -->
<!-- plot(y,type="l") -->

<!-- #plot(merge(x,y), multi.panel = TRUE, type = "l") -->

<!-- forcast_gjr_top = ugarchforecast(fitORspec = garch_sp500_fit_close, n.ahead = 12) -->
<!-- forcast_gjr_top -->

<!-- ############## NEW TEST GARCH ###################### -->

<!-- plot(forcast_gjr_top, which = "all" ) -->
<!-- #plot(garch_top_model) -->

<!-- forcast_gjr_top = ugarchforecast(fitORspec = forcast_gjr_top, n.ahead = 12) -->

<!-- plot(fitted(forcast_gjr_top)) -->
<!-- plot(sigma(forcast_gjr_top)) # from this we know we will have higher predicted volatility -->

<!-- x = sqrt(12)*sigma(forcast_gjr_top) -->

<!-- an_volatility = 0.15 # 15% of anualized risk -->
<!-- w = an_volatility/x # weights assigned to risky asset  -->

<!-- plot(merge(x,w), multi.panel = TRUE) -->
<!-- plot(x) -->
<!-- plot(w) -->


<!-- plot.zoo(fitted(sim)) -->
<!-- plot.zoo(sigma(sim)) -->

<!-- tail(ts_sp500_ret) -->

<!-- p = 1.035186 * apply(fitted(sim),2,'cumsum') + 1.035186 # calculating the change in price -->
<!-- matplot(p, type = "l", lwd = 3) -->
<!-- ``` -->
# ```{r}
# mean_sp500 = mean(ts_sp500_ret)
# errors = ts_sp500_ret - mean_sp500
# 
# par(mfrow = c(2,1),mar = c(3, 2, 2, 2)) # ??
# plot(abs(errors))
# 
# plot(abs(e))
# acf(abs(errors))
# 
# error2 = errors^2 
# ```

```{r}
library(rugarch)

temp_top_ret = month_ret_tot %>%  dplyr::select("ret_mont_top","date") %>% arrange(date)
ts_temp_top_ret = ts(temp_top_ret[,1], start = c(2000, 10), freq = 12)

#auto.arima(ts_temp_top_ret,D=1, approximation = FALSE, lambda = lambda, parallel = TRUE, stepwise=FALSE, num.cores = 20 )

garchspec = ugarchspec(mean.model = list(armaOrder = c(0,0)),
                        variance.model = list(model = "gjrGARCH"), 
                        distribution.model = "sstd")

# Estimate the model
garchfit = rugarch::ugarchfit(data = ts_temp_top_ret  , spec = garchspec)

# Use the method sigma to retrieve the estimated volatilities 
garchvol = sigma(garchfit)

# Plot the volatility for 2008
plot(garchvol)

sqrt(uncvariance(garchfit))

devtools::unload("rugarch")
```

# ```{r}
# # da må vi gjøre det slik 
# # Når den er under 2.14 går alt til top, ved økning til 3 legger man det til 
# 
# cumalative_ret_dynamic = function (portfolio,portfolio2, gjr_vol){ # Defining function
#   reb_month =  unique(portfolio$date) # finds each re-balancing months from the portfolio
#   tot_ret = c() # empty vector 
#   vt_weights = vt_weights %>% as_tibble()
#   start_value = 1 # as of 1 USD 
#   top_start_val = start_value * vt_weights[1,1] #%>% as_tibble()
#   #bot_start_val = start_value - top_start_val# %>% as_tibble()
#   #bot_start_val = start_value * 1-vt_weights[1] 
#     for (i in 1:length(reb_month)){ # for each date we have in the portfolio do this 
#       if (gjr_vol[i,1] >= 2.4){
#         
#       } 
#       if (i == 1){  # First round do this 
#         z = portfolio %>% dplyr::filter(reb_month[i] == portfolio$date) # Select the first date on the list, filter out the rest
#         x = portfolio2 %>% dplyr::filter(reb_month[i] == portfolio2$date)
#         ret_z = top_start_val[1,1] * (1+z$return) * z$vw  
#         ret_x = bot_start_val[1,1] * (1+x$return) * x$vw
#         tot_ret[i]  = sum(ret_z, ret_x) 
#       }
#       if (i > 1){ # When its beyond start date, (t+1). Do the following
#         z = portfolio %>% dplyr::filter(reb_month[i] == portfolio$date) # Select the first date on the list, filter out the rest
#         x = portfolio2 %>% dplyr::filter(reb_month[i] == portfolio2$date)
#         ret_weights_z = vt_weights[i,1] * tot_ret[i-1] 
#         ret_weights_x = 1-vt_weights[i,1] * tot_ret[i-1]
#         ret_z = ret_weights_z[1,1] * z$vw * (1+z$return)  
#         ret_x = ret_weights_x[1,1] * x$vw * (1+x$return)
#         tot_ret[i]  = sum(ret_z, ret_x) # Sum it all up to reinvest 
#     }
#   }
# return(tot_ret) #returns the calculations out of the loop
# }
# 
# library(timetk)
# 
# top_2 = top_1 %>% dplyr::filter(date > "2008-10-01")
# bot_2 = bot_1 %>% dplyr::filter(date > "2008-10-01")
# garchvol1 = garchvol %>% as.data.frame()
# garchvol1 = cbind(garchvol1, total_score)
# colnames(garchvol1)[1] = "gjr_vol" 
# garchvol1 = garchvol1 %>% dplyr::select(c("gjr_vol","date"))
# garchvol1 = garchvol1 %>% dplyr::filter(date > "2008-10-01")
# 
# gjr_vol = garchvol1 
# 
# top_dynamic = cumalative_ret_dynamic(top_1,bot_1,garchvol1) # runs the script on top portfolio 
# #mid_score = cumalative_ret_portfolio(mid) # runs on bot portf.
# #bot_score = cumalative_ret_portfolio(bot) # runs on bot portf.
# 
# top_dynamic %>% plot(type = "line")
# ```

```{r}
# da må vi gjøre det slik 
# Når den er under 2.14 går alt til top, ved økning til 3 legger man det til 
# portfolio = top_2
# portfolio2 = bot_2
# gjr_vol = garchvol1

cumalative_ret_dynamic = function (portfolio,portfolio2, gjr_vol){ # Defining function
  reb_month =  unique(portfolio$date) # finds each re-balancing months from the portfolio
  tot_ret = c() # empty vector 
  border = 2.2
    for (i in 1:length(reb_month)){ # for each date we have in the portfolio do this 
      if (i == 1){ 
        if (gjr_vol[i,1] >= border){
          x = portfolio2 %>% dplyr::filter(reb_month[i] == portfolio2$date)
          ret_x = (1+x$return) * x$vw
          tot_ret[i] = sum(ret_x)
        } 
        else {
          z = portfolio %>% dplyr::filter(reb_month[i] == portfolio$date)
          ret_z = (1+z$return) * z$vw
          tot_ret[i] = sum(ret_z)
              }
                }
      if (i > 1){ 
          if (gjr_vol[i,1] <= border){
            x = portfolio2 %>% dplyr::filter(reb_month[i] == portfolio2$date)
            ret_x = tot_ret[i-1] * (1+x$return) * x$vw
            tot_ret[i] = sum(ret_x)
          }
          else{
            z = portfolio %>% dplyr::filter(reb_month[i] == portfolio$date)
            ret_z = tot_ret[i-1] * (1+z$return) * z$vw
            tot_ret[i] = sum(ret_z)
          }
        }
    }
  return(tot_ret) #returns the calculations out of the loop
  }


top_2 = top_1 %>% dplyr::filter(date > "2000-10-01")
bot_2 = bot_1 %>% dplyr::filter(date > "2000-10-01")
garchvol1 = garchvol %>% as.data.frame()
garchvol1 = cbind(garchvol1, total_score)
colnames(garchvol1)[1] = "gjr_vol" 
rownames(garchvol1)=NULL
garchvol1 = garchvol1 %>% arrange(date) %>% dplyr::select(c("gjr_vol","date"))
garchvol1 = garchvol1 %>% dplyr::filter(date > "2000-10-01")

top_dynamic = cumalative_ret_dynamic(top_1,bot_1,garchvol1) # runs the script on top portfolio 
#mid_score = cumalative_ret_portfolio(mid) # runs on bot portf.
#bot_score = cumalative_ret_portfolio(bot) # runs on bot portf.

top_dynamic %>% plot(type = "l")

arrange(total_score,date)
tot_score_final = cbind(total_score, top_dynamic)

tot_score_final %>% tail()


```

```{r}
colors = c("top" = "blue", "bot" = "orange", "dynamic" = "green", " cu_ff_mkt_rf" = "red", " sp500" = "black")

ggplot(total_score, aes(x = date)) + # Uses main dataset
       geom_line(aes(y = top, color = "top"), size = 1) +
       geom_line(aes(y = bot, color = "bot"), size = 1) + 
       geom_line(aes(y = top_dynamic, color = "green"), size = 1) + 
       geom_line(aes(y = sp500_cumret, color = "sp500"), size = 1)+
       labs(x = 'Date',
       y = 'Cumulative Returns',
       title = 'Portfolio Cumulative Returns') +
    scale_y_continuous(breaks = seq(0,10,1)) +
    scale_x_date(date_breaks = '5 year',
               date_labels = '%Y') +
    scale_color_manual(values = colors)
```

################
################ Works to down here. Cant get dynamic to work like it should.
################



```{r}
library(parallel)

#temp_top_ret = month_ret_tot %>%  dplyr::select("ret_mont_top","date") %>% arrange(date)
#ts_temp_top_ret = ts(temp_top_ret[,1], start = c(2000, 10), freq = 12)

temp_top_ret = month_ret_tot %>%  dplyr::select("ret_mont_top","date") %>% arrange(date)
#temp_top_ret = temp_top_ret[,1] / 100
ts_temp_top_ret = ts(temp_top_ret[1:100,1] /100, start = c(2000, 10), freq = 12)

temp_norm_top_ret = month_ret_tot %>%  dplyr::select("norm_ret_mont_top","date") %>% arrange(date)
temp_norm_top_ret = temp_norm_top_ret %>% log()
temp_norm_top_ret = ts(temp_norm_top_ret[1:100,1] /100, start = c(2000, 10), freq = 12)



garchspec = ugarchspec(mean.model = list(armaOrder = c(0,0)),
                       variance.model = list(model = "gjrGARCH"),
                       garchOrder = c(1,1),
                       distribution.model = "sstd")

cl = makePSOCKcluster(25)

ugarch_roll = rugarch::ugarchroll(spec = garchspec, # garchspec model 
                                  data = temp_norm_top_ret, #inn data 
                                  n.start = 1, # when to start wtesting
                                  forecast.length = 1, #how far to forcast ( idealy this should be a trading month in days.) But we have 1 month instead
                                  refit.every = 6, # How often to refit (6 months is from the paper (or 126 trading days))
                                  refit.window = "moving", # Moving window to test 
                                  solver = "hybrid",  # Solver to use 
                                  calculate.VaR = TRUE,  # Calculate Value at risk or not 
                                  solver.control = list(tol = 1e-12),   # Solver controll 
                                  VaR.alpha = 0.19,  # 19 % var from paper 
                                  cluster = cl,  # initates cluster computing
                                  keep.coef = TRUE # keeping the coeficients 
                                  )

show(ugarch_roll)
stopCluster(cl)
plot(ugarch_roll)

# nå kjører vi regresion mellom kalkulert volatility og GJR volatility


predic = as.data.frame(ugarch_roll)

sigma_reg = lm(predic$Sigma ~  temp_norm_top_ret )



month_ret_tot$top_vol[61:nrow(month_ret_tot)] %>% plot(type = "l")

#ff_reg = lm(return_wml_reg ~  ff_mkt_rf + ff_smb + ff_hml, data = total_score)
weights_pred = lm(predic$Realized ~  predic$Sigma)

error = predic$Realized - predic$Mu
div = error ^ 2 - predic$Sigma ^ 2
mean(div^2)

x = sqrt(12)*ugarch_roll@forecast$density$Sigma

an_volatility = 0.15 # 15% of anualized risk
w = an_volatility/x # weights assigned to risky asset 

plot(x, type = "l")

#ts_spp = 1.035186 * apply(fitted(sim),2,'cumsum') + 1.035186 # calculating the change in price
#matplot(p, type = "l", lwd = 3)

report(ugarch_roll, typ = "VaR", VaR.alpha = 0.19, conf.level = 0.99)
```

```{r}
library(fGarch)

Fit01 =  garchFit(~ garch(1,1), data=temp_norm_top_ret, cond.dist="norm", include.mean = FALSE, trace = FALSE)
Fit01

Fit01@fit$ics

res1  = ts_temp_top_ret/Fit01@sigma.t  

plot(ts_temp_top_ret)
plot(Fit01@sigma.t, type="l") 

ts_1_temp_top_ret = ts_temp_top_ret %>% as.xts()

sigma.upper = xts(1.96*Fit01@sigma.t, order.by=index(ts_1_temp_top_ret))
sigma.lower = xts(-1.96*Fit01@sigma.t, order.by=index(ts_1_temp_top_ret))
    
plot( cbind(ts_temp_top_ret, sigma.upper, sigma.lower),
    col=c("black", "red", "red"), lwd=c(2,1,1) )

plot(  as.numeric(ts_1_temp_top_ret["2000::"]), type="h", lwd=2)
lines( as.numeric(sigma.upper["2000::"]), col="red")
lines( as.numeric(sigma.lower["2000::"]), col="red")
```

# ```{r}
# library(Hmisc)
# # en timeseries frem til 2008
#
# temp_top_ret = month_ret_tot %>%  dplyr::select("ret_mont_top","date") %>% arrange(date)
# #temp_top_ret = temp_top_ret[,1] / 100
# ts_temp_top_ret = ts(temp_top_ret[1:80,1] /100, start = c(2000, 10), freq = 12)
#
# # Så fitter man modellen til en GJR modell, lektyren anbefaler 1,1 garch
#
# garch_sp500_spec = ugarchspec(mean.model = list(armaOrder = c(0,0)),
#                    variance.model = list(model = "gjrGARCH", garchOrder = c(1, 1)),
#                    distribution.model = 'sstd')
#
# garch_top_fit_close = ugarchfit(garch_sp500_spec, temp_norm_top_ret)
#
# # Så gjør vi bare det i 2008 på predictions
# forcast_gjr_top = ugarchforecast(fitORspec = garch_top_fit_close, n.ahead = 12)
#
# mu. <- fitted(garch_top_fit_close)
# sig. <- sigma(garch_top_fit_close)
#
#
# # Plot forecast
# plot(forcast_gjr_top, which=1)
# plot(forcast_gjr_top, which=3)
#
#
# #jo Høyere volatility predcition jo høyere investering MEN BARE I NEDE TIDEN
# forcast_gjr_top %>% plot()
# ```


# ```{r, investigating timeseries bot}
# testing_ts(ts_bot_ret,6)
# ```

```{r}
# ts_garch = ts_df %>% as.data.frame()
# ts_garch = df %>% dplyr::filter(quantile == 10)
# ts_garch = cbind(ts_test, ts_garch)
```


## Chris stuff ------------------------------------------------- IDK what this is???

```{r, 6 month forwardlooking returns?}
# This creates 12 cols, these cols will tell you if you sold it today, what will be the return 

ret_1_6 = function (portfolio){ # Defining function
  uniq_stocks =  unique(portfolio$symbol) # finds each stock to calc returns
  temp_holder = 0 %>% as.data.frame()
  temp_holder2 = 0 %>% as.data.frame()
  temp_holder3 = 0 %>% as.data.frame()
  count = 0
  pb = txtProgressBar(min = 0, max = nrow(portfolio), initial = 0, style = 3) # progress bar
   z = 0 %>% as.data.frame()
  for (i in 1:nrow(portfolio)){ # for each date we have in the portfolio do this
      z = portfolio[i,]
      count = count + 1 # Adds 1 to the counter for progressbar 
      setTxtProgressBar(pb,count) # Starting the progress bar
      for(j in 1:6) {
        #temp_holder  = momentum(z$return, n=j)
        temp_holder = portfolio$wml[6+j+count]
        name = paste0("mom", sep = "_", j)
        z[[name]] =  temp_holder 
        if (j == 6){
          temp_holder2  = bind_rows(temp_holder2, z)
        } 
     }
    }
  return(temp_holder2)
}  

test  = ret_1_6(total_score)
test = test %>% dplyr::distinct(date, .keep_all = T)

wml_chris = test %>% slice(-c(1)) # Due to bind with one Zero, there is a redundant row, this is removed here. 
test = NULL 
```

```{r, forcast calculations}
# Return forcast ! 

wml_chris$forcast = (wml_chris$mom_6 / wml_chris$mom_1)^(1/6) 

wml_chris$forcast = ((wml_chris$forcast - 1)*100) # n[t-1]

wml_chris$forcast_2 = ((((wml_chris$forcast)^2 - wml_chris$forcast)^2)) #sigma^2[t-1]

wml_chris %>% head()
```

```{r, volatility calculations}

vol_calc = function (data){
  out = volatility(data, n = 6, calc = "close", N = 12, mean0 = FALSE)
  return(out)
}

month_ret_tot$top_vol = vol_calc(month_ret_tot$norm_ret_mont_top)
month_ret_tot$sp500_vol =  vol_calc(month_ret_tot$norm_ret_sp500)
month_ret_tot$bot_vol = vol_calc(month_ret_tot$norm_ret_mont_bot)

```

```{r, forcasting????}
### Now we can get the lambda

month_ret_tot$lambda = month_ret_tot$sp500_vol / sqrt(wml_chris$forcast_2) %>% as_tibble()

#### Now we can finaly get the weights 

wml_chris$weights_forcast = (1/month_ret_tot$lambda) * (wml_chris$forcast / wml_chris$forcast_2)
wml_chris$weights_forcast

```





