---
title: "Data retrival and random selection of 100 sample stocks"
output: html_notebook
---

```{r}
library(tidyquant)
library(tidyverse)
library(dplyr)
library(plyr)
#library(plyr)
```

# ```{r}
# library(devtools)
# devtools::install_github("business-science/tidyquant")
# ```


```{r}
  library(doParallel)
  library(snow)
  library(doSNOW)

 cl <- makeCluster(detectCores()-1, type = "SOCK")

 call_cluster_init = function(cl){
   registerDoParallel(cl)
}
```

```{r}

nyse = tq_exchange("NYSE")
nasdaq = tq_exchange("NASDAQ")
amex = tq_exchange("AMEX")

sp500_list = tq_index("SP500")

#all_ticks = rbind(nyse,nasdaq,amex) 
#all_ticks = all_ticks$symbol
all_ticks = sp500_list$symbol 
```

```{r}
total_loop_time = proc.time() #Starts timer 
tot_df = tq_get(all_ticks,
                     from = '1960-01-01',
                     to = '2021-10-24',
                     get = "stock.prices")
sp500_df = tot_df
save(sp500_df, file="sp500_df.Rdata")
#write.csv(tot_df,"/home/nnx/Machinelearning 1/Momentum-Crashes/tot_df_db.csv", row.names = FALSE)
proc.time() - total_loop_time #stops timer     
```


```{r}
numb_stocks = 1000

temp_stock = unique(tot_df$symbol)
random_stocks = sample(1:length(temp_stock), numb_stocks, replace= FALSE) 
#random_stocks_test = sample(1:30, 5, replace= FALSE)
```


```{r}
filter_data = NULL

total_loop_time = proc.time() #Starts timer 

randomizer = function(x){
  filter_data = tot_df %>% filter(symbol == temp_stock[random_stocks[x]])
  return(filter_data)
}


call_cluster_init()

packs = c("tidyverse","dplyr")

random_stocks = foreach (i = 1:numb_stocks, .packages = packs ) %dopar% {
                         filter_data = tot_df %>% filter(symbol == temp_stock[random_stocks[x]])
                         return(filter_data)
                         }

stopCluster(cl)


#df = ldply(random_stocks)
#df = subset(df, select = -c(value)) #removing a redundant column

proc.time() - total_loop_time #stops timer  


#save(df, file="df1000.Rdata")
```








# ```{r, find autotuned all primary filtred features for rpart}
# total_loop_time = proc.time() #Starts timer 
# 
# tot_df = NULL # creates an empty variable
# 
# call_cluster_init() # Calling the cluster to do parallel processing 
# 
# total_loop_time = proc.time() #Starts timer 
# 
# # list_packs= c("tidyquant")
# 
# tot_df = foreach (i = 1:length(all_ticks), .packages = "tidyquant") %dopar% {
#   funk = funk_df(i)
#   return(funk)
# }
# 
# #tot_df = ldply(tot_df) #converting from large list to data frame
# 
# proc.time() - total_loop_time #stops timer                    
# 
# 
# stopCluster(cl)
# 
# save(tot_df, file="tot_df.Rdata")
# ```
   



# ```{r}
# #tickers = c('BND', 'VB', 'VEA', 'VOO', 'VWO', 'aapl', 'msft')
# 
# #Old stocks pre year 1911
# tickers = c('xom', 'ge', 'cvx', 'ibm', 'cl', 'pg', 'jnj', 'jpm','pfe', 'ko', 'wfc', 'c', 'bac', 'mrk', 'pep', 'abt', 'gs', 'ups', 'mmm', 'axp', 'f', 'cvs', 'usb', 'unp', 'bmy', 'dd', 'met', 'lly', 'dow', 'EMR')
# 
# # Asset weights
# tick_leng = 1/length(tickers)
# eq_wts = c(rep(tick_leng, length(tickers))) # Creates a 1/n weighting
# 
# wts = c(0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033,0.033) #All weights sett to 1/30, due to copy paste
# 
# price_data <- tq_get(tickers,
#                      from = '1969-01-01',
#                      to = '2020-12-31',
#                      get = "stock.prices") #'stock.prices')#, 'dividends', 'splits', 'economic.data')
# 
# ret_data <- price_data %>%
#   group_by(symbol) %>%
#   tq_transmute(select = adjusted, #NB! always use adjusted! Due to close does not take into considiration stocksplits dividents etc. 
#                mutate_fun = periodReturn,
#                period = "daily",
#                col_rename = "ret")
# 
# wts_tbl <- tibble(symbol = tickers,
#                   wts = wts)
# ret_data <- left_join(ret_data,wts_tbl, by = 'symbol')
# 
# ret_data <- ret_data %>%
#   mutate(wt_return = wts * ret)
# 
# port_ret <- ret_data %>%
#   group_by(date) %>%
#   summarise(port_ret = sum(wt_return))
# 
# port_cumulative_ret <- port_ret %>%
#   mutate(cr = cumprod(1 + port_ret))
# 
# save(ret_data, file="ret_data.Rdata")
# ```

