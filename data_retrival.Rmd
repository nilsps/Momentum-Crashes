---
title: "Data retrival and random selection of 100 sample stocks"
output: nils
---

```{r}
library(tidyquant)
library(tidyverse)
library(dplyr)
library(plyr)
library(plyr)
```

```{r}
##
# This sections registers the do parallel for your computer.
##

   library(doParallel)
   library(snow)
   library(doSNOW)

cl <- makeCluster(detectCores()-2, type = "SOCK") #Finds max hypertread on your pc minus two (for stability) 

call_cluster_init = function(cl){ # Creates a funtion to call under parallalization  
   registerDoParallel(cl)
 }
```

```{r}

nyse = tq_exchange("NYSE") # Retrives all tickers from NYSE
nasdaq = tq_exchange("NASDAQ")# Same but Nasdaq  
amex = tq_exchange("AMEX") # Amex   

amex$exchange = "AMEX" 
nyse$exchange = "NYSE"
nasdaq$exchange = "NASDAQ" 





all_ticks = rbind(nyse,nasdaq,amex) # Binds all stockmarkets together  
#all_ticks = all_ticks$symbol # MAkes a variable where all tickers are found 
names(all_ticks)[3] = "last_sales_price" 
names(all_ticks)[4] = "market_cap"
names(all_ticks)[6] = "ipo_year"

all_ticks[is.na(all_ticks)] = 0

#glimpse(all_ticks)


#write.csv(all_ticks, file = "Overview.csv", row.names = FALSE)



# Saving ram, as these are not needed anymore. 
#nyse = NULL
#nasdaq = NULL
#amex = NULL
```

```{r}
##
# THIS TAKES A LONG TIME, To save time adjust dates as it retrives all stocks available and omits stocks without historical data 
##


total_loop_time = proc.time() #Starts timer 
tot_df = tq_get(all_ticks,
                     from = '1960-01-01',
                     to = '2021-10-24',
                     get = "stock.prices")
#save(tot_df, file="tot_df.Rdata") # Untick this box to save data to your disk  
#write.csv(tot_df,"/home/nnx/Machinelearning 1/Momentum-Crashes/tot_df_db.csv", row.names = FALSE) #Write it as csv to your disk. This file is 3-5 times bigger then .Rdata but can be used in databases, excel etc. 
proc.time() - total_loop_time #stops timer Just to see how long it uses 
```


```{r}
filter_data = NULL # Creates empty variable 
numb_stocks = 5000  # Set to lower number to get less random drawn stocks.

temp_stock = unique(tot_df$symbol) # Find all the uniqe ticker from previously downloded data
random_stocks = sample(1:length(temp_stock), numb_stocks, replace= FALSE) # Creates a random sample of numb_stocks from the entire stock universe. 
```

# ```{r}
# total_loop_time = proc.time()
# filter_data = NULL
# 
# randomizer = function(x){
#   filter_data = tot_df %>% filter(symbol == temp_stock[random_stocks[x]])
#   return(filter_data)
# }
# 
# random_stocks = lapply(1:numb_stocks, randomizer)
# 
# df = ldply(random_stocks)
# df = subset(df, select = -c(value)) #removing a redundant column
# 
# save(df, file="df.Rdata")
# proc.time() - total_loop_time
# ```

```{r}

#####################################
########
######## DO NOT RUN! UNLESS PC HAS OVER 45GB OF RAM @ 30 cores/parallels      
########  USE CHUNK ABOVE IF ON REGULAR COMPUTER!
########     CAN OVERLOAD PC AT MAX CORES
########
#####################################
total_loop_time = proc.time() # Timer 

call_cluster_init() # Calling the parallel clustering

packs_needed = c("tidyverse", "dplyr") # Need to call packs inside parallelization, or else they do not exist within the loop- 

para_loop = foreach (i = 1:numb_stocks, .packages=packs_needed) %dopar% { # makes a loop  
                      filter_data = tot_df %>% filter(symbol == temp_stock[random_stocks[i]]) # filter out all stocks that are not "picked" by the random generator 
                      return(filter_data) # returns data
}

df = ldply(para_loop) # This is here to convert from x amount data from para_loop into single dataset.
df = subset(df, select = -c(value)) #removing a redundant column

save(df, file="df.Rdata") #Saving the data to the pc 
stopCluster(cl) # Closing down the computing cluster 
proc.time() - total_loop_time # stops the timer 

# Freeing up ram as these are not needed anymore
para_loop = NULL
tot_df = NULL

###
## All data seems to be inorder to this point
###

tot_df = subset(tot_df, select = -c(value)) #removing a redundant column
write.csv(tot_df, file = "tot_df_db.csv", row.names = FALSE)
```

####
## Testing set for program flow. 
####
# #tickers = c('BND', 'VB', 'VEA', 'VOO', 'VWO', 'aapl', 'msft')
# 
# #Old stocks pre year 1911
# tickers = c('xom', 'ge', 'cvx', 'ibm', 'cl', 'pg', 'jnj', 'jpm','pfe', 'ko', 'wfc', 'c', 'bac', 'mrk', #'pep', 'abt', 'gs', 'ups', 'mmm', 'axp', 'f', 'cvs', 'usb', 'unp', 'bmy', 'dd', 'met', 'lly', 'dow', 'EMR')


